{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4 * 56 = 224\\n\\nEn español: 4 veces 56 es 224.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = OllamaLLM(model=\"mistral:latest\", temperature=0)\n",
    "llm.invoke(\"Me puedes decir cuanto es 4*56\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for multiply\na\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Me puedes decir cuánto es 4*56', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nb\n  Field required [type=missing, input_value={'a': 'Me puedes decir cuánto es 4*56'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m a * b\n\u001b[32m      6\u001b[39m llm_with_tools = RunnableParallel(\n\u001b[32m      7\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mllm\u001b[39m\u001b[33m\"\u001b[39m: llm, \u001b[33m\"\u001b[39m\u001b[33mmultiply\u001b[39m\u001b[33m\"\u001b[39m: multiply}  \u001b[38;5;66;03m# Usar directamente la función decorada\u001b[39;00m\n\u001b[32m      8\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMe puedes decir cuánto es 4*56\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3734\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3729\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3730\u001b[39m         futures = [\n\u001b[32m   3731\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3732\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3733\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3734\u001b[39m         output = {key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[32m   3735\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3736\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3718\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input, config, key)\u001b[39m\n\u001b[32m   3716\u001b[39m context = copy_context()\n\u001b[32m   3717\u001b[39m context.run(_set_config_context, child_config)\n\u001b[32m-> \u001b[39m\u001b[32m3718\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3722\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:509\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    503\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    504\u001b[39m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m, ToolCall],\n\u001b[32m    505\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    506\u001b[39m     **kwargs: Any,\n\u001b[32m    507\u001b[39m ) -> Any:\n\u001b[32m    508\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:763\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    762\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    764\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    765\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:727\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    725\u001b[39m context = copy_context()\n\u001b[32m    726\u001b[39m context.run(_set_config_context, child_config)\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    729\u001b[39m     tool_kwargs = tool_kwargs | {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:649\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    642\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    643\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m ):\n\u001b[32m    647\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:541\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    539\u001b[39m key_ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_fields(input_args).keys()))\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(input_args, \u001b[33m\"\u001b[39m\u001b[33mmodel_validate\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    543\u001b[39m     input_args.parse_obj({key_: tool_input})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/pydantic/main.py:627\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context)\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    626\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 2 validation errors for multiply\na\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Me puedes decir cuánto es 4*56', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nb\n  Field required [type=missing, input_value={'a': 'Me puedes decir cuánto es 4*56'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplica dos números enteros.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = RunnableParallel(\n",
    "    {\"llm\": llm, \"multiply\": multiply}  # Usar directamente la función decorada\n",
    ")\n",
    "\n",
    "response = llm_with_tools.invoke(\"Me puedes decir cuánto es 4*56\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps__={'llm': OllamaLLM(model='deepseek-r1:latest', temperature=0.0), 'multiply': StructuredTool(name='multiply', description='Multiplica dos números enteros.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x77f3792163e0>)}\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for multiply\na\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Calcula 4 por 56 usando ...nta de multiplicación.', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nb\n  Field required [type=missing, input_value={'a': 'Calcula 4 por 56 u...ta de multiplicación.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     25\u001b[39m llm_with_tools = RunnableParallel(\n\u001b[32m     26\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mllm\u001b[39m\u001b[33m\"\u001b[39m: llm, \u001b[33m\"\u001b[39m\u001b[33mmultiply\u001b[39m\u001b[33m\"\u001b[39m: multiply}  \u001b[38;5;66;03m# Correcto: pasa la función decorada como herramienta\u001b[39;00m\n\u001b[32m     27\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(llm_with_tools)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCalcula 4 por 56 usando la herramienta de multiplicación.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Invocar el modelo con herramientas activadas\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#response = llm_with_tools.invoke(\"Me puedes decir cuánto es 4*56\")\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m#print(response)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3734\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3729\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3730\u001b[39m         futures = [\n\u001b[32m   3731\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3732\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3733\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3734\u001b[39m         output = {key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[32m   3735\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3736\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3718\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input, config, key)\u001b[39m\n\u001b[32m   3716\u001b[39m context = copy_context()\n\u001b[32m   3717\u001b[39m context.run(_set_config_context, child_config)\n\u001b[32m-> \u001b[39m\u001b[32m3718\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3722\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:509\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    503\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    504\u001b[39m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m, ToolCall],\n\u001b[32m    505\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    506\u001b[39m     **kwargs: Any,\n\u001b[32m    507\u001b[39m ) -> Any:\n\u001b[32m    508\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:763\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    762\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    764\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    765\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:727\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    725\u001b[39m context = copy_context()\n\u001b[32m    726\u001b[39m context.run(_set_config_context, child_config)\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    729\u001b[39m     tool_kwargs = tool_kwargs | {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:649\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    642\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    643\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m ):\n\u001b[32m    647\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain_core/tools/base.py:541\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    539\u001b[39m key_ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_fields(input_args).keys()))\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(input_args, \u001b[33m\"\u001b[39m\u001b[33mmodel_validate\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    543\u001b[39m     input_args.parse_obj({key_: tool_input})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/pydantic/main.py:627\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context)\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    626\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 2 validation errors for multiply\na\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Calcula 4 por 56 usando ...nta de multiplicación.', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\nb\n  Field required [type=missing, input_value={'a': 'Calcula 4 por 56 u...ta de multiplicación.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "# Cargar variables de entorno\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Definir la herramienta correctamente con el decorador @tool\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplica dos números enteros.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Configurar el modelo de lenguaje\n",
    "llm = OllamaLLM(\n",
    "    model=\"deepseek-r1:latest\",\n",
    "    temperature=0,\n",
    "    system=\"Si necesitas hacer cálculos matemáticos, usa la herramienta de multiplicación.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Configurar la ejecución con herramientas\n",
    "llm_with_tools = RunnableParallel(\n",
    "    {\"llm\": llm, \"multiply\": multiply}  # Correcto: pasa la función decorada como herramienta\n",
    ")\n",
    "\n",
    "print(llm_with_tools)\n",
    "\n",
    "response = llm_with_tools.invoke(\"Calcula 4 por 56 usando la herramienta de multiplicación.\")\n",
    "\n",
    "# Invocar el modelo con herramientas activadas\n",
    "#response = llm_with_tools.invoke(\"Me puedes decir cuánto es 4*56\")\n",
    "#print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps__={'llm': OllamaLLM(model='mistral:latest', temperature=0.0), 'multiply': StructuredTool(name='multiply', description='Extrae dos números de una consulta en texto y los multiplica.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x77f36ec28540>)}\n",
      "{\n",
      "    \"llm\": \"4 x 56 = 224\\n\\nEn este caso, puedes multiplicar los números uno a uno:\\n\\n- Primero, multiplica 4 por 6 (4 * 6 = 24)\\n- Después, multiplica el resultado por 5 (24 * 5 = 120)\\n- Finalmente, multiplica el resultado por 1 (120 * 1 = 120)\\n\\nPero es más fácil usar la herramienta de multiplicación:\\n\\n- Empieza en la columna de los números mayores y sigue hacia la izquierda hasta llegar a la columna de los números menores.\\n- En cada intersección, si hay un número en ambas columnas, entonces multiplica ese número por el número que está debajo de él en la columna de los números mayores y suma el resultado a la fila correspondiente en la tabla de multiplicar.\\n- En este caso, 4 está en la primera fila y 56 está en la sexta columna. Multiplica 4 por 6 (24) y suma el resultado a la fila 0: 0 + 24 = 24. Luego multiplica 4 por 5 (20) y suma el resultado a la fila 1: 24 + 20 = 44. Finalmente, multiplica 4 por 1 (4) y suma el resultado a la fila 2: 44 + 4 = 48.\\n- Ahora, sigue hacia la izquierda hasta llegar a la columna de los números menores. Multiplica 4 por 56 (224) y suma el resultado a la fila 3: 48 + 224 = 272.\\n- Por último, multiplica 0 por 56 (0), pero no lo sumas a ninguna fila porque ya has terminado de llenar la tabla.\\n\\nEl resultado final es 272.\",\n",
      "    \"multiply\": 224\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Cargar variables de entorno\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Definir la herramienta correctamente con el decorador @tool\n",
    "@tool\n",
    "def multiply(query: str) -> int:\n",
    "    \"\"\"Extrae dos números de una consulta en texto y los multiplica.\"\"\"\n",
    "    numbers = [int(num) for num in re.findall(r'\\d+', query)]\n",
    "    if len(numbers) == 2:\n",
    "        return numbers[0] * numbers[1]\n",
    "    return \"Error: No se encontraron dos números en la consulta.\"\n",
    "\n",
    "# Configurar el modelo de lenguaje con herramientas\n",
    "llm = OllamaLLM(\n",
    "    model=\"mistral:latest\",  # Puedes probar con otros modelos como gemma:latest o llama3:latest\n",
    "    temperature=0,\n",
    "    system=\"Si necesitas hacer cálculos matemáticos, usa la herramienta de multiplicación.\"\n",
    ")\n",
    "\n",
    "# Vincular herramientas usando RunnableParallel\n",
    "llm_with_tools = RunnableParallel(\n",
    "    {\"llm\": llm, \"multiply\": multiply}\n",
    ")\n",
    "\n",
    "# Verificar que la herramienta está registrada correctamente\n",
    "print(llm_with_tools)\n",
    "\n",
    "# Probar invocación\n",
    "response = llm_with_tools.invoke(\"Calcula 4 por 56 usando la herramienta de multiplicación.\")\n",
    "\n",
    "# Imprimir la respuesta en formato JSON para ver si la herramienta se usa correctamente\n",
    "import json\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_openai_functions_agent() missing 1 required positional argument: 'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     21\u001b[39m llm = OllamaLLM(\n\u001b[32m     22\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mmistral:latest\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# Puedes probar con otros modelos como gemma:latest o llama3:latest\u001b[39;00m\n\u001b[32m     23\u001b[39m     temperature=\u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     )\n\u001b[32m     29\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Crear un agente que use el LLM y la herramienta\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m agent = \u001b[43mcreate_openai_functions_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmultiply\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Crear un ejecutor de agente\u001b[39;00m\n\u001b[32m     35\u001b[39m agent_executor = AgentExecutor(agent=agent, tools=[multiply], verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: create_openai_functions_agent() missing 1 required positional argument: 'prompt'"
     ]
    }
   ],
   "source": [
    "# Cargar variables de entorno\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Definir la herramienta correctamente con el decorador @tool\n",
    "@tool\n",
    "def multiply(query: str) -> str:\n",
    "    \"\"\"Extrae dos números de una consulta en texto y los multiplica.\"\"\"\n",
    "    numbers = [int(num) for num in re.findall(r'\\d+', query)]\n",
    "    if len(numbers) == 2:\n",
    "        return f\"{numbers[0] * numbers[1]}\"\n",
    "    return \"Error: No se encontraron dos números en la consulta.\"\n",
    "\n",
    "# Configurar el modelo de lenguaje con instrucciones claras\n",
    "llm = OllamaLLM(\n",
    "    model=\"mistral:latest\",  # Puedes probar con otros modelos como gemma:latest o llama3:latest\n",
    "    temperature=0,\n",
    "    system=(\n",
    "        \"Si necesitas hacer cálculos matemáticos, usa exclusivamente la herramienta de multiplicación.\\n\"\n",
    "        \"No intentes resolver cálculos por tu cuenta.\\n\"\n",
    "        \"Siempre delega cualquier operación matemática a la herramienta disponible.\\n\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Crear un agente que use el LLM y la herramienta\n",
    "agent = create_openai_functions_agent(llm, [multiply])\n",
    "\n",
    "# Crear un ejecutor de agente\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[multiply], verbose=True)\n",
    "\n",
    "# Probar invocación\n",
    "response = agent_executor.invoke({\"input\": \"Calcula 4 por 56 usando la herramienta de multiplicación.\"})\n",
    "\n",
    "# Imprimir la respuesta\n",
    "import json\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'input_variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     33\u001b[39m prompt = ChatPromptTemplate.from_messages([\n\u001b[32m     34\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEres un asistente experto en matemáticas. Siempre usas la herramienta \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmultiply\u001b[39m\u001b[33m'\u001b[39m\u001b[33m para multiplicar números.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     35\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m ])\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Crear un agente que use el LLM, el prompt y la herramienta\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m agent = \u001b[43mcreate_openai_functions_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmultiply\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Crear un ejecutor de agente\u001b[39;00m\n\u001b[32m     42\u001b[39m agent_executor = AgentExecutor(agent=agent, tools=[multiply], verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langchain/agents/openai_functions_agent/base.py:354\u001b[39m, in \u001b[36mcreate_openai_functions_agent\u001b[39m\u001b[34m(llm, tools, prompt)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_openai_functions_agent\u001b[39m(\n\u001b[32m    282\u001b[39m     llm: BaseLanguageModel, tools: Sequence[BaseTool], prompt: ChatPromptTemplate\n\u001b[32m    283\u001b[39m ) -> Runnable:\n\u001b[32m    284\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create an agent that uses OpenAI function calling.\u001b[39;00m\n\u001b[32m    285\u001b[39m \n\u001b[32m    286\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m \u001b[33;03m            )\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33magent_scratchpad\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m         \u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput_variables\u001b[49m + \u001b[38;5;28mlist\u001b[39m(prompt.partial_variables)\n\u001b[32m    355\u001b[39m     ):\n\u001b[32m    356\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    357\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPrompt must have input variable `agent_scratchpad`, but wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt found. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt.input_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    359\u001b[39m         )\n\u001b[32m    360\u001b[39m     llm_with_tools = llm.bind(functions=[convert_to_openai_function(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools])\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'input_variables'"
     ]
    }
   ],
   "source": [
    "# Cargar variables de entorno\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Definir la herramienta correctamente con el decorador @tool\n",
    "@tool\n",
    "def multiply(query: str) -> str:\n",
    "    \"\"\"Extrae dos números de una consulta en texto y los multiplica.\"\"\"\n",
    "    numbers = [int(num) for num in re.findall(r'\\d+', query)]\n",
    "    if len(numbers) == 2:\n",
    "        return f\"{numbers[0] * numbers[1]}\"\n",
    "    return \"Error: No se encontraron dos números en la consulta.\"\n",
    "\n",
    "# Configurar el modelo de lenguaje con instrucciones claras\n",
    "llm = OllamaLLM(\n",
    "    model=\"mistral:latest\",  # Puedes probar con otros modelos como gemma:latest o llama3:latest\n",
    "    temperature=0,\n",
    "    system=(\n",
    "        \"Si necesitas hacer cálculos matemáticos, usa exclusivamente la herramienta de multiplicación.\\n\"\n",
    "        \"No intentes resolver cálculos por tu cuenta.\\n\"\n",
    "        \"Siempre delega cualquier operación matemática a la herramienta disponible.\\n\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Definir un prompt base para el agente\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un asistente experto en matemáticas. Siempre usas la herramienta 'multiply' para multiplicar números.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Crear un agente que use el LLM, el prompt y la herramienta\n",
    "agent = create_openai_functions_agent(llm, prompt, [multiply])\n",
    "\n",
    "# Crear un ejecutor de agente\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[multiply], verbose=True)\n",
    "\n",
    "# Probar invocación\n",
    "response = agent_executor.invoke({\"input\": \"Calcula 4 por 56 usando la herramienta de multiplicación.\"})\n",
    "\n",
    "# Imprimir la respuesta\n",
    "import json\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4340/2310706049.py:33: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent_executor = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use the multiply tool to calculate 4 times 56.\n",
      "Action: multiply\n",
      "Action Input: \"4, 56\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m224\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The result of 4 multiplied by 56 is 224.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"input\": \"Calcula 4 por 56 usando la herramienta de multiplicación.\",\n",
      "    \"output\": \"The result of 4 multiplied by 56 is 224.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Cargar variables de entorno\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor, initialize_agent, AgentType\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Definir la herramienta correctamente con el decorador @tool\n",
    "@tool\n",
    "def multiply(query: str) -> str:\n",
    "    \"\"\"Extrae dos números de una consulta en texto y los multiplica.\"\"\"\n",
    "    numbers = [int(num) for num in re.findall(r'\\d+', query)]\n",
    "    if len(numbers) == 2:\n",
    "        return f\"{numbers[0] * numbers[1]}\"\n",
    "    return \"Error: No se encontraron dos números en la consulta.\"\n",
    "\n",
    "# Configurar el modelo de lenguaje con instrucciones claras\n",
    "llm = OllamaLLM(\n",
    "    model=\"mistral:latest\",  # Puedes probar con otros modelos como gemma:latest o llama3:latest\n",
    "    temperature=0,\n",
    "    system=(\n",
    "        \"Si necesitas hacer cálculos matemáticos, usa exclusivamente la herramienta de multiplicación.\\n\"\n",
    "        \"No intentes resolver cálculos por tu cuenta.\\n\"\n",
    "        \"Siempre delega cualquier operación matemática a la herramienta disponible.\\n\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Inicializar el agente con las herramientas\n",
    "agent_executor = initialize_agent(\n",
    "    tools=[multiply],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # Modo basado en razonamiento\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Probar invocación\n",
    "response = agent_executor.invoke({\"input\": \"Calcula 4 por 56 usando la herramienta de multiplicación.\"})\n",
    "\n",
    "# Imprimir la respuesta\n",
    "import json\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OllamaLLM' object has no attribute 'bind_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m     messages: List\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Crear el agente ReAct en LangGraph (sin pasar `prompt`)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m agent = \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmultiply\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Construir el flujo de ejecución con LangGraph\u001b[39;00m\n\u001b[32m     44\u001b[39m workflow = StateGraph(AgentState)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py:157\u001b[39m, in \u001b[36m_convert_modifier_to_prompt.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m     prompt = _convert_messages_modifier_to_prompt(messages_modifier)\n\u001b[32m    156\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m] = prompt\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py:632\u001b[39m, in \u001b[36mcreate_react_agent\u001b[39m\u001b[34m(model, tools, state_schema, prompt, response_format, checkpointer, store, interrupt_before, interrupt_after, debug, version, name)\u001b[39m\n\u001b[32m    629\u001b[39m tool_calling_enabled = \u001b[38;5;28mlen\u001b[39m(tool_classes) > \u001b[32m0\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _should_bind_tools(model, tool_classes) \u001b[38;5;129;01mand\u001b[39;00m tool_calling_enabled:\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     model = \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBaseChatModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_tools\u001b[49m(tool_classes)\n\u001b[32m    634\u001b[39m model_runnable = _get_prompt_runnable(prompt) | model\n\u001b[32m    636\u001b[39m \u001b[38;5;66;03m# If any of the tools are configured to return_directly after running,\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m# our graph needs to check if these were called\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/practises/langgraph/.venv/lib/python3.12/site-packages/pydantic/main.py:891\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    890\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'OllamaLLM' object has no attribute 'bind_tools'"
     ]
    }
   ],
   "source": [
    "# Cargar variables de entorno\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from typing import TypedDict, List\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Definir la herramienta correctamente con el decorador @tool\n",
    "@tool\n",
    "def multiply(query: str) -> str:\n",
    "    \"\"\"Extrae dos números de una consulta en texto y los multiplica.\"\"\"\n",
    "    numbers = [int(num) for num in re.findall(r'\\d+', query)]\n",
    "    if len(numbers) == 2:\n",
    "        return f\"{numbers[0] * numbers[1]}\"\n",
    "    return \"Error: No se encontraron dos números en la consulta.\"\n",
    "\n",
    "# Definir el modelo de lenguaje con instrucciones claras\n",
    "llm = OllamaLLM(\n",
    "    model=\"mistral:latest\",  # Puedes probar con otros modelos como gemma:latest o llama3:latest\n",
    "    temperature=0,\n",
    "    system=(\n",
    "        \"Eres un asistente experto en matemáticas.\\n\"\n",
    "        \"Si necesitas hacer cálculos matemáticos, usa exclusivamente la herramienta de multiplicación.\\n\"\n",
    "        \"No intentes resolver cálculos por tu cuenta.\\n\"\n",
    "        \"Siempre delega cualquier operación matemática a la herramienta disponible.\\n\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Definir el estado del agente en LangGraph\n",
    "class AgentState(TypedDict):\n",
    "    messages: List\n",
    "\n",
    "# Crear el agente ReAct en LangGraph (sin pasar `prompt`)\n",
    "agent = create_react_agent(llm, [multiply])\n",
    "\n",
    "# Construir el flujo de ejecución con LangGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Agregar el nodo del agente al gráfico\n",
    "workflow.add_node(\"agent\", agent)\n",
    "\n",
    "# Configurar la transición entre nodos (solo tenemos el agente por ahora)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Construir el ejecutor de LangGraph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Probar invocación en LangGraph\n",
    "response = app.invoke({\"messages\": [HumanMessage(content=\"Calcula 4 por 56 usando la herramienta de multiplicación.\")]})\n",
    "\n",
    "# Imprimir la respuesta\n",
    "import json\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
